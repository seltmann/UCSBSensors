{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:00:00\n",
      "2020-04\n",
      "['A000536', 'A000563', 'A000507', 'A000466', 'A000369', 'A000318', 'A000522', 'A000546', 'A000465', 'A000229', 'A000513']\n",
      "[' Lagoon 2016 Burn', ' Stipa Loam NCOS', ' BlackLakeGentleSo', ' NCOS Saltmarsh', ' SaltMarshMilkVetch', ' LagoonCoastalSage', ' Philips 66 Nipomo', ' NCOS 2017 Stipa', ' CampusPtIceplant', ' LagoonAnnualGrass', ' BlackLakeN-facing']\n",
      "2020\n",
      "C:/Users/15303/Documents/ Lagoon 2016 Burn/Daily/2020/\n",
      "C:/Users/15303/Documents/ Lagoon 2016 Burn/Hourly/2020/\n",
      "C:/Users/15303/Documents/ Lagoon 2016 Burn/Soil/2020/\n",
      "C:/Users/15303/Documents/ Lagoon 2016 Burn/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ Stipa Loam NCOS/Daily/2020/\n",
      "C:/Users/15303/Documents/ Stipa Loam NCOS/Hourly/2020/\n",
      "C:/Users/15303/Documents/ Stipa Loam NCOS/Soil/2020/\n",
      "C:/Users/15303/Documents/ Stipa Loam NCOS/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ BlackLakeGentleSo/Daily/2020/\n",
      "C:/Users/15303/Documents/ BlackLakeGentleSo/Hourly/2020/\n",
      "C:/Users/15303/Documents/ BlackLakeGentleSo/Soil/2020/\n",
      "C:/Users/15303/Documents/ BlackLakeGentleSo/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ NCOS Saltmarsh/Daily/2020/\n",
      "C:/Users/15303/Documents/ NCOS Saltmarsh/Hourly/2020/\n",
      "C:/Users/15303/Documents/ NCOS Saltmarsh/Soil/2020/\n",
      "C:/Users/15303/Documents/ NCOS Saltmarsh/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ SaltMarshMilkVetch/Daily/2020/\n",
      "C:/Users/15303/Documents/ SaltMarshMilkVetch/Hourly/2020/\n",
      "C:/Users/15303/Documents/ SaltMarshMilkVetch/Soil/2020/\n",
      "C:/Users/15303/Documents/ SaltMarshMilkVetch/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ LagoonCoastalSage/Daily/2020/\n",
      "C:/Users/15303/Documents/ LagoonCoastalSage/Hourly/2020/\n",
      "C:/Users/15303/Documents/ LagoonCoastalSage/Soil/2020/\n",
      "C:/Users/15303/Documents/ LagoonCoastalSage/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ Philips 66 Nipomo/Daily/2020/\n",
      "C:/Users/15303/Documents/ Philips 66 Nipomo/Hourly/2020/\n",
      "C:/Users/15303/Documents/ Philips 66 Nipomo/Soil/2020/\n",
      "C:/Users/15303/Documents/ Philips 66 Nipomo/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ NCOS 2017 Stipa/Daily/2020/\n",
      "C:/Users/15303/Documents/ NCOS 2017 Stipa/Hourly/2020/\n",
      "C:/Users/15303/Documents/ NCOS 2017 Stipa/Soil/2020/\n",
      "C:/Users/15303/Documents/ NCOS 2017 Stipa/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ CampusPtIceplant/Daily/2020/\n",
      "C:/Users/15303/Documents/ CampusPtIceplant/Hourly/2020/\n",
      "C:/Users/15303/Documents/ CampusPtIceplant/Soil/2020/\n",
      "C:/Users/15303/Documents/ CampusPtIceplant/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ LagoonAnnualGrass/Daily/2020/\n",
      "C:/Users/15303/Documents/ LagoonAnnualGrass/Hourly/2020/\n",
      "C:/Users/15303/Documents/ LagoonAnnualGrass/Soil/2020/\n",
      "C:/Users/15303/Documents/ LagoonAnnualGrass/Calibrated/2020/\n",
      "C:/Users/15303/Documents/ BlackLakeN-facing/Daily/2020/\n",
      "C:/Users/15303/Documents/ BlackLakeN-facing/Hourly/2020/\n",
      "C:/Users/15303/Documents/ BlackLakeN-facing/Soil/2020/\n",
      "C:/Users/15303/Documents/ BlackLakeN-facing/Calibrated/2020/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nfor j in range(len(Data_Types)):\\n    if not os.path.exists(Folder_Names[j]):\\n        os.makedirs(Folder_Names[j])\\n        print \"Directory \" , Folder_Names[j] ,  \" Created \"\\n    else:    \\n        print \"Directory \" , Folder_Names[j] ,  \" already exists\"  \\n        pass\\n    for dev in device_ids:\\n        print(dev)\\n        write_csv_file(start_current_month, today, Data_Types[j], Sub_Sub_Folder_Names[j], Folder_Names[j], dt_to_ym(start_current_month), Column_Names[j], dev)\\n        \\n    '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arable\n",
    "from   arable.client     import ArableClient \n",
    "a = ArableClient()\n",
    "from   sensor_includes   import email, password_ccber, tenant_ccber\n",
    "\n",
    "a.connect(email = email, password = password_ccber, tenant = tenant_ccber)\n",
    "\n",
    "from   datetime          import timedelta\n",
    "from   datetime          import datetime\n",
    "\n",
    "\n",
    "import pandas            as     pd\n",
    "\n",
    "dt = datetime.now()\n",
    "\n",
    "from   io                import StringIO\n",
    "\n",
    "from arable_data_dict import Calibrated_Data_Columns, Hourly_Data_Columns, Daily_Data_Columns\n",
    "\n",
    "# Datetime object to string with format \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "def dt_to_ymd_hms(x):\n",
    "    return x.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "# Append string with format \"%Y-%m-%dT%H:%M:%SZ\" to list\n",
    "def append_ymd_hms(a, b):\n",
    "    a.append(dt_to_ymd_hms(b))\n",
    "# Reverses dt_to_ymd_hms\n",
    "def ymd_hms_to_dt(x):\n",
    "    return datetime.strptime(x, \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "# Datetime object to string with format \"%Y-%m-%d\"\n",
    "def dt_to_ymd(x):\n",
    "    return x.strftime(\"%Y-%m-%d\")\n",
    "# Reverse dt_to_ymd\n",
    "def ymd_to_dt(x):\n",
    "    return datetime.strptime(x, \"%Y-%m-%d\")\n",
    "\n",
    "# Datetime object to string with format \"%Y-%m\"\n",
    "def dt_to_ym(x):\n",
    "    return x.strftime(\"%Y-%m\")\n",
    "# Append string with format \"%Y-%m\" to list\n",
    "def append_ym(a, b):\n",
    "    try:\n",
    "        a.append(dt_to_ym(b))\n",
    "    except:\n",
    "        a.append(dt_to_ym(ym_to_dt(b)))\n",
    "# Reverse dt_to_ym\n",
    "def ym_to_dt(x):\n",
    "    return datetime.strptime(x, \"%Y-%m\")\n",
    "\n",
    "# Append string to list\n",
    "def append_string(a, b):\n",
    "    a.append(str(b))\n",
    "    \n",
    "# Append temporary lists to list\n",
    "def append_temp_list(temp_list, main_list):\n",
    "    main_list.append(temp_list)\n",
    "\n",
    "def arable_query(s, b, c, d, e, f, g):\n",
    "    df = a.query( select = str(s),\n",
    "                  format = str(b),\n",
    "                 devices = c,\n",
    "                 measure = str(d),\n",
    "                   order = str(e),\n",
    "                     end = f,\n",
    "                   start = g,\n",
    "                   limit = 5000) #100000000)\n",
    "    df = StringIO(df)\n",
    "    df = pd.read_csv(df, sep=',', error_bad_lines=False)\n",
    "    return df\n",
    "\n",
    "start_current_month = ym_to_dt(dt_to_ym(dt)).replace(day=1)\n",
    "print(start_current_month)\n",
    "print(dt_to_ym(start_current_month))\n",
    "\n",
    "today = dt\n",
    "\n",
    "import os\n",
    "# dirpath = 'C:/Users/ccber-arables/Box/'\n",
    "dirpath = 'C:/Users/15303/Documents/'\n",
    "\n",
    "def write_csv_file(sta, end, data_type, data_type_fn, folder, cm, m, device): \n",
    "    logfile = 'Log_' + str(dt_to_ymd(today)) + '.txt'\n",
    "    devicee = \"['\" + str(device) + \"']\"\n",
    "    #col = ['sdi12_version', 'sdi12_vendor_id', 'sdi12_sensor_model', 'sdi12_sensor_version', 'sdi12_sensor_sn']\n",
    "    fn = str(folder) + str(devicee)[2:-2] + '_' + str(cm) + '_' + str(data_type_fn) + '.csv'\n",
    "    print(fn)\n",
    "    try:\n",
    "        df = a.query(select = 'all', \n",
    "                     format = 'csv', \n",
    "                     devices = devicee, \n",
    "                     measure = str(data_type), \n",
    "                     order = \"time\", \n",
    "                     end = end, \n",
    "                     start = sta, \n",
    "                     limit = 100000000)\n",
    "        df = StringIO(df)\n",
    "        df = pd.read_csv(df, sep=',', error_bad_lines=False)\n",
    "        df = df.dropna(axis='columns', thresh=2)#how='all')\n",
    "        df = df.drop('location', 1)\n",
    "        df = df.rename(mapper=m)\n",
    "        df.to_csv(fn, sep = \",\")\n",
    "        print('Successfully wrote ' + fn)\n",
    "        open(logfile, 'a+').write('Successfully wrote ' + fn + '\\n')\n",
    "    except:\n",
    "        open(logfile, 'a+').write('Failure writing ' + fn + '\\n')\n",
    "        pass  \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "device_ids = pd.read_csv(str('Sensor-Info_' + str(dt_to_ymd(dt)) + '.txt'), sep = \",\")['ID'].values.tolist()    \n",
    "print(device_ids) \n",
    "locations  = pd.read_csv(str('Sensor-Info_' + str(dt_to_ymd(dt)) + '.txt'), sep = \",\")['Location'].values.tolist()  \n",
    "print(locations)\n",
    "\n",
    "# ---> YEAR\n",
    "# --------> MONTH\n",
    "# --------------> DATA TYPE\n",
    "# ------------------------> DEVICE-ID_MONTH-YEAR_DATA-TYPE.csv\n",
    "Folder_Name          = start_current_month.strftime(\"%Y\")\n",
    "print(Folder_Name)\n",
    "# Sub_Folder_Name      = start_current_month.strftime(\"%m\")\n",
    "Sub_Sub_Folder_Names = [\"Daily\", \"Hourly\", \"Soil\", \"Calibrated\"]\n",
    "Data_Types           = [\"daily\", \"hourly\", \"aux_raw\", \"health\"]\n",
    "Column_Names         = [Calibrated_Data_Columns, Hourly_Data_Columns, Hourly_Data_Columns, Daily_Data_Columns]\n",
    "\n",
    "Folder_Name_B        = [str(str(Sub_Sub_Folder_Names[i]) + '/' + str(Folder_Name) + '/') for i in range(len(Sub_Sub_Folder_Names))]\n",
    "\n",
    "\n",
    "for i in range(len(locations)):\n",
    "    Folder_Name_A = str(dirpath + str(locations[i]) + '/')\n",
    "    for j in range(len(Folder_Name_B)):\n",
    "        Folder_Name = str(Folder_Name_A + Folder_Name_B[j])\n",
    "        print(Folder_Name)\n",
    "\n",
    "'''\n",
    "\n",
    "for j in range(len(Data_Types)):\n",
    "    if not os.path.exists(Folder_Names[j]):\n",
    "        os.makedirs(Folder_Names[j])\n",
    "        print \"Directory \" , Folder_Names[j] ,  \" Created \"\n",
    "    else:    \n",
    "        print \"Directory \" , Folder_Names[j] ,  \" already exists\"  \n",
    "        pass\n",
    "    for dev in device_ids:\n",
    "        print(dev)\n",
    "        write_csv_file(start_current_month, today, Data_Types[j], Sub_Sub_Folder_Names[j], Folder_Names[j], dt_to_ym(start_current_month), Column_Names[j], dev)\n",
    "        \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                         Name\n",
      "tair_version                                          UNKNOWN\n",
      "B1uw                      Spectrometer data Bands 1 upwelling\n",
      "LWdw                       Long wave downwelling, hourly mean\n",
      "Tair                                          Air temperature\n",
      "SWuw                        Short wave upwelling, hourly mean\n",
      "Tabove                                        Sky temperature\n",
      "Tbelow                                Leaf/Ground temperature\n",
      "B5uw                      Spectrometer data Bands 1 upwelling\n",
      "RH                                          Relative humidity\n",
      "B7uw                      Spectrometer data Bands 1 upwelling\n",
      "B3dw                    Spectrometer data Bands 1 downwelling\n",
      "B5dw                    Spectrometer data Bands 1 downwelling\n",
      "PARdw         Photosynthetically Active Radiation downwelling\n",
      "B2uw                      Spectrometer data Bands 1 upwelling\n",
      "B3uw                      Spectrometer data Bands 1 upwelling\n",
      "PARuw           Photosynthetically Active Radiation upwelling\n",
      "P                                                    Pressure\n",
      "B7dw                    Spectrometer data Bands 1 downwelling\n",
      "B4uw                      Spectrometer data Bands 1 upwelling\n",
      "B2dw                    Spectrometer data Bands 1 downwelling\n",
      "B6uw                      Spectrometer data Bands 1 upwelling\n",
      "B4dw                    Spectrometer data Bands 1 downwelling\n",
      "B6dw                    Spectrometer data Bands 1 downwelling\n",
      "B1dw                    Spectrometer data Bands 1 downwelling\n",
      "LWuw                         Long wave upwelling, hourly mean\n",
      "SWdw                      Short wave downwelling, hourly mean\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "    df = pd.DataFrame.from_dict(dictionary, orient='index', dtype='string', columns=[colname])\n",
    "    return df\n",
    "\n",
    "CalibratedDF       = importcolnames(Calibrated_Data_Columns, 'Name')\n",
    "HourlyDF           = importcolnames(Hourly_Data_Columns, 'Name')\n",
    "DailyDF            = importcolnames(Daily_Data_Columns, 'Name')\n",
    "\n",
    "CalibratedDF_Units = importcolnames(Calibrated_Data_Columns_Units, 'Units')\n",
    "HourlyDF_Units     = importcolnames(Hourly_Data_Columns_Units, 'Units')\n",
    "DailyDF_Units      = importcolnames(Daily_Data_Columns_Units, 'Units')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
